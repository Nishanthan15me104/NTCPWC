## End-to-end data flow
```
Query
 ‚Üì
Hybrid Retriever
   ‚îú‚îÄ Text FAISS
   ‚îî‚îÄ (Optional) Image FAISS
 ‚Üì
Retrieved Documents
 ‚Üì
Generator
 ‚Üì
Prompt
 ‚Üì
LLM
 ‚Üì
Answer
```

COMPLETE MULTIMODAL RAG DATA FLOW (START ‚Üí END)
STAGE 0 ‚Äî RAW INPUT
Input
PDF file (e.g. Amrit_Kaal_Vision_2047.pdf)

Nature

Unstructured

Mixed modalities:

Text

Images

Layout

LLMs cannot consume this directly.

STAGE 1 ‚Äî MULTIMODAL PROCESSOR (PDF ‚Üí STRUCTURED DATA)
Component

MultimodalProcessor

Responsibility

Convert PDF ‚Üí reusable structured state

1.1 TEXT EXTRACTION (PyMuPDF / fitz)

Each page is read independently.

Data produced (in memory)
[
  {
    "text": "Full text of page 1 ...",
    "page_num": 1
  },
  {
    "text": "Full text of page 2 ...",
    "page_num": 2
  }
]


‚úî Page number preserved
‚úî Text still raw, not chunked

1.2 IMAGE EXTRACTION (pdf2image + OpenCV)
Step-by-step transformation (per page)
PDF page
 ‚Üí PIL Image
 ‚Üí NumPy Array
 ‚Üí OpenCV Image
 ‚Üí Grayscale
 ‚Üí Threshold
 ‚Üí Contour Detection
 ‚Üí Bounding Boxes
 ‚Üí Cropped Images

Filter logic
Ignore small contours (noise)
Keep large regions ‚Üí likely figures/diagrams

1.3 IMAGE FILE OUTPUT (Disk)

Each detected image is saved as:

data/extracted/images/img_<page>_<n>.png


Example:

img_47_3.png

1.4 IMAGE METADATA (in memory)
{
  "image_id": "img_47_3",
  "page_num": 47,
  "path": "data/extracted/images/img_47_3.png"
}

1.5 FINAL METADATA STATE (Saved to Disk)

üìÅ data/extracted/metadata.json

{
  "text": [
    {
      "text": "Text from page 1 ...",
      "page_num": 1
    },
    ...
  ],
  "images": [
    {
      "image_id": "img_47_3",
      "page_num": 47,
      "path": "data/extracted/images/img_47_3.png"
    },
    ...
  ]
}


üß† This is the SINGLE SOURCE OF TRUTH for the entire system

STAGE 2 ‚Äî IMAGE ‚Üí TEXT (CAPTIONING PIPELINE)
Component

BLIP Image Captioning

Why?

Vector databases work on text, not pixels.

2.1 Image Loading

Each .png file is loaded as:

PIL.Image ‚Üí RGB

2.2 Caption Generation (BLIP)
Image
 ‚Üí Vision Encoder
 ‚Üí Language Decoder
 ‚Üí Caption


Example caption:

"A cover page showing a ship at sea with government branding"

2.3 IMAGE DOCUMENT OBJECT

Each image becomes a LangChain Document:

{
  "page_content": "A cover page showing a ship at sea...",
  "metadata": {
    "page_num": 1,
    "image": "img_1_1.png"
  }
}


üìå Important:

Image is now semantic text

Page alignment is preserved

2.4 IMAGE EMBEDDING

Caption ‚Üí Vector (via bge-small-en-v1.5)

Caption text ‚Üí 384-dim embedding

2.5 IMAGE FAISS INDEX (Disk)

üìÅ data/faiss/images/

Stores:

Vector

Caption

Page number

Image filename

STAGE 3 ‚Äî TEXT CHUNKING & INDEXING
Component

Text Index Builder

3.1 Load Text from Metadata
{
  "text": [
    { "text": "...", "page_num": 1 }
  ]
}

3.2 TEXT DOCUMENT OBJECT

Each page becomes:

{
  "page_content": "Full page text...",
  "metadata": {
    "page_num": 1
  }
}

3.3 CHUNKING (RecursiveCharacterTextSplitter)

Parameters:

chunk_size = 800
chunk_overlap = 100

Result
Page
 ‚Üí Chunk 1
 ‚Üí Chunk 2
 ‚Üí Chunk 3


Each chunk keeps:

{
  "page_num": 1
}

3.4 TEXT EMBEDDING

Each chunk ‚Üí vector using same embedding model

üß† Why same model?

Shared vector space

Enables cross-modal reasoning

3.5 TEXT FAISS INDEX (Disk)

üìÅ data/faiss/text/

Stores:

Chunk vectors

Chunk text

Page metadata

STAGE 4 ‚Äî QUERY-TIME RETRIEVAL
Component

MaritimeHybridRetriever

4.1 User Query

Example:

"Describe the cover image of the document"

4.2 QUERY EMBEDDING
Query text ‚Üí vector


Same embedding model ‚Üí same vector space

4.3 TEXT RETRIEVAL (Always)
Query vector
 ‚Üí FAISS (text)
 ‚Üí Top 5 chunks


Output:

[
  {
    "page_content": "...",
    "metadata": { "page_num": 1 }
  }
]

4.4 VISUAL INTENT DETECTION

If query contains:

image, visual, cover, figure, diagram...


‚û° Trigger image retrieval

4.5 PAGE ALIGNMENT LOGIC

From text results:

Relevant pages = {1, 2}


This prevents unrelated image hallucinations.

4.6 IMAGE RETRIEVAL (Conditional)
Query vector
 ‚Üí FAISS (images)
 ‚Üí Top 10 captions
 ‚Üí Filter by relevant pages


Output:

{
  "page_content": "A cover page showing a ship...",
  "metadata": {
    "page_num": 1,
    "image": "img_1_1.png"
  }
}

4.7 FINAL RETRIEVAL OUTPUT
[Text chunks] + [Image captions]

STAGE 5 ‚Äî CONTEXT CONSTRUCTION
Component

MaritimeGenerator

5.1 CONTEXT FORMAT
[Text | Page 1]: ...
[Visual | Page 1 | img_1_1.png]: ...


üß† Why?

Explicit modality labeling

Forces grounded reasoning

STAGE 6 ‚Äî LLM ANSWER GENERATION
Model
llama-3.3-70b-versatile

Prompt Structure
Use ONLY the context below.
CONTEXT:
...
Question:
Answer:

Output
Final grounded answer

STAGE 7 ‚Äî METRICS & EVALUATION
Measured

Text retrieval time

Image retrieval time

LLM response time

Total latency

Stored as
{
  "Query": 3,
  "Text Retrieval (s)": 0.21,
  "Image Retrieval (s)": 0.34,
  "LLM Response (s)": 1.82,
  "Total Time (s)": 2.45
}

üß† FINAL ONE-LINE FLOW (MEMORIZE THIS)

PDF ‚Üí Structured Metadata ‚Üí Text & Image Indices ‚Üí Conditional Multimodal Retrieval ‚Üí Grounded Prompt ‚Üí LLM Answer